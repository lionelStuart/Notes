监控系统包括metric、log和trace

以metric和log为中心，trace做上下游微服务关联

## metrics

metric按角色可分为运维和应用层两个场景，两者关注的指标有差异：

运维更关注从机器-》资源-》服务的使用率状态，如机器和服务维度CPU、MEM、IO、DISK和各服务存活状态、资源使用情况

应用层关注SLA、耗时、QPS和一些特定业务的打点统计数据

实时的
metrics数据可以分为推拉两种形式，如普罗米修斯拉数据，可以看作定期采样，不适合精确度要求高的场景

数值要求高的metrics应该用推数据


## log

存储日志利用，可以做trace故障分析，也可以做OLTP。OLTP场景做天级分析也可实现metrics的部分功能，做汇聚报表。做trace分析则需要结合trace组件功能，也需要metrics做入口。

log的使用场景更丰富，使用趋向是metric+log+trace合一



# 学习内容

# 普罗米修斯和grafana

1. 普罗米修斯和grafana的搭建
- 普罗修斯配置、定期任务、服务端口、UI
- 定义持久化存储

2. mysql、node接入普罗米修斯监控
- 定义数据源
- 接入exporter
- 导入dashboard


3. 服务自定义监控接入普罗米修斯
- 定义定时任务
- API开发


# 链路追踪、skywalking、EFK
1. 创建Elastic和kibana，打开前端页面

2. 从golang程序写支持elastic解析的日志

3. 配置filebeat通用模板，以sidecar接入golang程序

4. 配置kibana界面，日志导入成功

5. 定制化配置elastic，关闭SSL，配置持久化

6. 关注点
    - 以https模式接入filebeat配置校验为false
    - docker CMD指令不能直接使用重定向符号，需要用脚本支持
    - 边车中指定的路径需要一致
    - filebeat可以用指令测试配置和输出是否正确

7. 架构设计考量
- 数据收集汇总面临归并的问题

如日志系统数据，服务数：ES集群数规模，为保护下游机器且不会因为吞吐问题影响上游数据，通过Kafka消费来自Filebeat的数据并写入中间层的Logstash，由Logstash负责写入到ES

如trace链路数据收集，有相同的问题，但单次数据量小，且要求的延时更低，相比消息系统消费，更适合设置Proxy的方式来处理。


日志分析系统，对延时的要求更低，批次消费，flink


- 架构设计考量要素

目标、成本(花多少钱做多少事，或者说，在限制条件下达成什么效果)

Trace\Metric\LOG\OLAP

要求:时效性、规模、可靠性

时效性（可靠性）：Trace-Metric>LOG>OLAP-Metric
规模：LOG=OLAP-Metric>>Trace-Metric

# 链路追踪系统 skywalking

1. 搭建OAP后端系统，需要选择合适版本，如果存储选择ES8，需要更高的版本

2. 搭建前端UI

3. 在开发应用中应用插件

对于java，可以应用client边车

对于golang，需要插件支持，在gin和http请求中注册tracer插件，对测试服务gate-way和下游服务gogo-api均注册该插件，并测试入口请求



